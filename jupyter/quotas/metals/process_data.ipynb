{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook header <--- Always run this cell first!\n",
    "import os, json\n",
    "import ruamel.yaml as yaml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from monty.json import MontyDecoder, MontyEncoder\n",
    "from pymatgen.io.vasp.outputs import Outcar, Vasprun\n",
    "from xml.etree.ElementTree import ParseError\n",
    "from quotas.core import QuotasCalculator, WorkFunctionData, DielTensor\n",
    "\n",
    "# Load the dictionary of all the structures for which we have calculated the required properties\n",
    "with open(\"structure_dict.yaml\", \"r\") as file:\n",
    "    structure_dict = yaml.safe_load(file.read())\n",
    "\n",
    "data_dir = \"/mnt/data/mbercx/quotas\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the QUOTAS data\n",
    "\n",
    "## Parsing the VASP output files.\n",
    "\n",
    "Calculating the secondary electron emission from the VASP output files is quite time consuming, as parsing the files is relatively slow. In order to quickly load the required data for calculating the SEE, it's better to store it as a QuotasCalculator JSON file for future use. The cell below defined some quick methods for processing the output files and writing a JSON file for each surface of each element. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_check(vasprun_file):\n",
    "    \n",
    "    try:\n",
    "        vr = Vasprun(vasprun_file)\n",
    "    except ParseError:\n",
    "        return False\n",
    "    except FileNotFoundError:\n",
    "        return False\n",
    "    \n",
    "    if not vr.converged or vr.dos_has_errors:\n",
    "        return False\n",
    "    \n",
    "    return vr\n",
    "\n",
    "def process_data(element, surfaces, functional=\"pbe\"):\n",
    "    \n",
    "    optics_dir = os.path.join(data_dir, element, \"bulk\", functional + \"_optics\")\n",
    "    \n",
    "    if load_and_check(os.path.join(optics_dir, \"vasprun.xml\")):\n",
    "    \n",
    "        diel = DielTensor.from_file(os.path.join(optics_dir, \"vasprun.xml\"))\n",
    "        out = Outcar(os.path.join(optics_dir, \"OUTCAR\"))\n",
    "        out.read_freq_dielectric()\n",
    "        plasma_frequencies = out.plasma_frequencies[\"intraband\"] ** (1/2)\n",
    "        diel.add_intraband_dieltensor(plasma_frequency=plasma_frequencies)\n",
    "        \n",
    "    else:\n",
    "        return \"optics_issue\"\n",
    "    \n",
    "    surface_issues = []\n",
    "    \n",
    "    for surface in surfaces:\n",
    "        \n",
    "        dos_dir = os.path.join(data_dir, element, surface, functional + \"_dos\")\n",
    "        dos_vr = load_and_check(os.path.join(dos_dir, \"vasprun.xml\"))\n",
    "        \n",
    "        if dos_vr:\n",
    "            \n",
    "            cdos = dos_vr.complete_dos\n",
    "            workfunction_data = WorkFunctionData.from_dir(dos_dir)\n",
    "\n",
    "            quotas = QuotasCalculator(\n",
    "                cdos=cdos,\n",
    "                workfunction_data=workfunction_data,\n",
    "                dieltensor=diel,\n",
    "                energy_spacing=0.05\n",
    "            )\n",
    "            quotas.to(os.path.join(\"data\", element + \"_\" + surface + \"_\" + functional + \".json\"))\n",
    "        else:\n",
    "            surface_issues.append(\"surface\" + \"_\" + surface + \"_issue\")\n",
    "            \n",
    "    if len(surface_issues) > 0:\n",
    "        return surface_issues\n",
    "    else:\n",
    "        return \"A-Okay!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below loops over all elements and processes their VASP output files. It also checks if there are any issues with the output, and stores these issues under `issues.json`. Because running this cell can take a lot of time, there is a possibility that the connection to the jupyter server is interrupted. In order to make sure we don't start from scratch after such an interruption, the issues are written to its .json file after each element, and the cell ignores elements which are already in the `issues.json` file. If you want to run this cell again from scratch, you have to remove or rename the `issues.json` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(\"issues.json\", \"r\") as file:\n",
    "        issue_dict = json.loads(file.read())\n",
    "except FileNotFoundError:\n",
    "    issue_dict = {}\n",
    "\n",
    "for element in structure_dict.keys():\n",
    "    if element not in issue_dict.keys():\n",
    "        issue_dict[element] = process_data(element, surfaces=structure_dict[element][\"slabs\"])\n",
    "        with open(\"issues.json\", \"w\") as file:\n",
    "            file.write(json.dumps(issue_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below was used to rerun the processing script for specific elements, once the issues with their calculations had been fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-88eff3347b12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0missue_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0missue_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msurfaces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstructure_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"slabs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"issues.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ''"
     ]
    }
   ],
   "source": [
    "element = \"\"\n",
    "\n",
    "with open(\"issues.json\", \"r\") as file:\n",
    "    issue_dict = json.loads(file.read())\n",
    "    \n",
    "issue_dict[element] = process_data(element, surfaces=structure_dict[element][\"slabs\"])\n",
    "\n",
    "with open(\"issues.json\", \"w\") as file:\n",
    "    file.write(json.dumps(issue_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ag': 'A-Okay!',\n",
       " 'Al': 'A-Okay!',\n",
       " 'As': 'A-Okay!',\n",
       " 'Au': 'A-Okay!',\n",
       " 'Ba': 'A-Okay!',\n",
       " 'Be': 'A-Okay!',\n",
       " 'Bi': 'A-Okay!',\n",
       " 'Ca': 'A-Okay!',\n",
       " 'Cd': 'A-Okay!',\n",
       " 'Co': 'A-Okay!',\n",
       " 'Cr_afm': ['surface_100_issue', 'surface_110_issue'],\n",
       " 'Cr_nm': 'A-Okay!',\n",
       " 'Cs': 'A-Okay!',\n",
       " 'Cu': 'A-Okay!',\n",
       " 'Fe_alpha': 'A-Okay!',\n",
       " 'Fe_gamma': 'A-Okay!',\n",
       " 'Ga': 'A-Okay!',\n",
       " 'Ge': 'A-Okay!',\n",
       " 'Hf': 'A-Okay!',\n",
       " 'Hg_alpha': 'A-Okay!',\n",
       " 'Hg_beta': 'A-Okay!',\n",
       " 'In': 'A-Okay!',\n",
       " 'Ir': 'A-Okay!',\n",
       " 'K': 'A-Okay!',\n",
       " 'Li': 'A-Okay!',\n",
       " 'Mg': 'A-Okay!',\n",
       " 'Mo': 'A-Okay!',\n",
       " 'Na': 'A-Okay!',\n",
       " 'Nb': 'A-Okay!',\n",
       " 'Ni': 'A-Okay!',\n",
       " 'Os': 'A-Okay!',\n",
       " 'Pb': 'A-Okay!',\n",
       " 'Pd': 'A-Okay!',\n",
       " 'Pt': 'A-Okay!',\n",
       " 'Rb': 'A-Okay!',\n",
       " 'Re': 'A-Okay!',\n",
       " 'Rh': 'A-Okay!',\n",
       " 'Ru': 'A-Okay!',\n",
       " 'Sb': 'A-Okay!',\n",
       " 'Sc': 'A-Okay!',\n",
       " 'Si': 'A-Okay!',\n",
       " 'Sn_alpha': 'A-Okay!',\n",
       " 'Sn_beta': 'A-Okay!',\n",
       " 'Sr': 'A-Okay!',\n",
       " 'Ta': 'A-Okay!',\n",
       " 'Tc': 'A-Okay!',\n",
       " 'Ti': 'A-Okay!',\n",
       " 'Tl': 'A-Okay!',\n",
       " 'V': 'A-Okay!',\n",
       " 'W': 'A-Okay!',\n",
       " 'Y': ['surface_001_issue'],\n",
       " 'Zn': 'A-Okay!',\n",
       " 'Zr': 'A-Okay!'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"issues.json\", \"r\") as file:\n",
    "    issue_dict = json.loads(file.read())\n",
    "issue_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a single dictionary with all of the yield results\n",
    "\n",
    "Loading the `QuotasCalculator` .json files is already a lot faster than initializing them from the VASP output files, but if we want to develop some interactive tools for analyzing the data, it would be better to calculate the yield for all the ionization energies and store these results directly as a dictionary. First we set the ionization energies for the chosen ions and define a little script that calculates the yield for all ions with a specified set of `plasmon_parameters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the effective ionization energies of the rare gas ions\n",
    "ionization_energies = {\n",
    "    \"He\": 24.59 - 2,\n",
    "    \"Ne\": 21.56 - 1,\n",
    "    \"Ar\": 15.76 - 0.5,\n",
    "    \"Kr\": 12.00,\n",
    "    \"Xe\": 10.13\n",
    "}\n",
    "\n",
    "def calculate_yield(quotas, plasmon_parameters=None):\n",
    "    \n",
    "    if plasmon_parameters is not None:\n",
    "        quotas.set_up_plasmon_probabilities(\n",
    "            bulk_parameter=plasmon_parameters[\"bulk\"],\n",
    "            surface_parameter=plasmon_parameters[\"surface\"]\n",
    "        )\n",
    "        \n",
    "    yield_dict = {}\n",
    "    for ion in ionization_energies.keys():\n",
    "        see = quotas.calculate_yield(ionization_energies[ion])\n",
    "        yield_dict[ion] = {\"energy\": see[\"energy\"], \n",
    "                           \"yield\": see[\"yield\"], \n",
    "                           \"total_yield\": see[\"total_yield\"]}\n",
    "    return yield_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we loop over all elements and gather all of their results into one dictionary of the following format:\n",
    "\n",
    "```python\n",
    "results_dict = {\n",
    "    <element> = {\n",
    "        \"bulk\": {\"dieltensor\": Dieltensor},\n",
    "        <surface1>: {\n",
    "            \"complete_dos\": CompleteDos,\n",
    "            \"workfunction_data\": WorkfunctionData,\n",
    "            \"yield_results\": {\n",
    "                \"energy\": see[\"energy\"], \n",
    "                \"yield\": see[\"yield\"], \n",
    "                \"total_yield\": see[\"total_yield\"]\n",
    "            }\n",
    "        }\n",
    "        <surface2>: {\n",
    "            ...\n",
    "        }\n",
    "        ...\n",
    "    }\n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "This takes quite a bit of time, and results in a rather large `.json` file that contains _all_ results for the bulk and surfaces of all elements. Note that the cell must complete without being interrupted, as the `results.json` file is only written at the end. This is because writing the file at every iteration slows down the process significantly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ag\n",
      "Al\n",
      "As\n",
      "Au\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mbercx/python/quotas/quotas/core.py:602: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  scatter_distribution, self.energies)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ba\n",
      "Be\n",
      "Bi\n",
      "Ca\n",
      "Cd\n",
      "Co\n",
      "Cr_afm\n",
      "Cr_nm\n",
      "Cs\n",
      "Cu\n",
      "Fe_alpha\n",
      "Fe_gamma\n",
      "Ga\n",
      "Ge\n",
      "Hf\n",
      "Hg_alpha\n",
      "Hg_beta\n",
      "In\n",
      "Ir\n",
      "K\n",
      "Li\n",
      "Mg\n",
      "Mo\n",
      "Na\n",
      "Nb\n",
      "Ni\n",
      "Os\n",
      "Pb\n",
      "Pd\n",
      "Pt\n",
      "Rb\n",
      "Re\n",
      "Rh\n",
      "Ru\n",
      "Sb\n",
      "Sc\n",
      "Si\n",
      "Sn_alpha\n",
      "Sn_beta\n",
      "Sr\n",
      "Ta\n",
      "Tc\n",
      "Ti\n",
      "Tl\n",
      "V\n",
      "W\n",
      "Y\n",
      "Zn\n",
      "Zr\n"
     ]
    }
   ],
   "source": [
    "results_dict = {element: {} for element in structure_dict.keys()}\n",
    "\n",
    "with open(\"issues.json\", \"r\") as file:\n",
    "    issue_dict = json.loads(file.read())\n",
    "    \n",
    "for element in structure_dict.keys():\n",
    "    \n",
    "    print(element)\n",
    "    \n",
    "    for surface in [surface for surface in structure_dict[element][\"slabs\"].keys() \n",
    "         if not 'surface_' + surface + '_issue' in issue_dict[element]]:\n",
    "\n",
    "        quotas = QuotasCalculator.from_file(\"data/\" + element + \"_\" + surface + \"_pbe.json\")\n",
    "        \n",
    "        if \"bulk\" not in results_dict[element].keys():\n",
    "            results_dict[element][\"bulk\"] = {\"dieltensor\": quotas.dieltensor}\n",
    "        \n",
    "        results_dict[element][surface] = {\n",
    "            \"complete_dos\": quotas.cdos,\n",
    "            \"workfunction_data\": quotas.workfunction_data,\n",
    "            \"yield_results\": calculate_yield(quotas)\n",
    "        }\n",
    "        \n",
    "with open(\"results.json\", \"w\") as file:\n",
    "    file.write(json.dumps(results_dict, cls=MontyEncoder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lightweight dictionary with all workfunctions/occupied band widths/yields.\n",
    "\n",
    "The `results.json` file generated above is rather massive, and contains way more data than is necessary for analyzing trends in the total yield / work function. Hence, we will also generate a smaller set of `.json` file that only contain the final results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ag\n",
      "Al\n",
      "As\n",
      "Au\n",
      "Ba\n",
      "Be\n",
      "Bi\n",
      "Ca\n",
      "Cd\n",
      "Co\n",
      "Cr_afm\n",
      "Cr_nm\n",
      "Cs\n",
      "Cu\n",
      "Fe_alpha\n",
      "Fe_gamma\n",
      "Ga\n",
      "Ge\n",
      "Hf\n",
      "Hg_alpha\n",
      "Hg_beta\n",
      "In\n",
      "Ir\n",
      "K\n",
      "Li\n",
      "Mg\n",
      "Mo\n",
      "Na\n",
      "Nb\n",
      "Ni\n",
      "Os\n",
      "Pb\n",
      "Pd\n",
      "Pt\n",
      "Rb\n",
      "Re\n",
      "Rh\n",
      "Ru\n",
      "Sb\n",
      "Sc\n",
      "Si\n",
      "Sn_alpha\n",
      "Sn_beta\n",
      "Sr\n",
      "Ta\n",
      "Tc\n",
      "Ti\n",
      "Tl\n",
      "V\n",
      "W\n",
      "Y\n",
      "Zn\n",
      "Zr\n"
     ]
    }
   ],
   "source": [
    "yield_dict = {element: {} for element in structure_dict.keys()}\n",
    "yield_np_dict = {element: {} for element in structure_dict.keys()}\n",
    "\n",
    "with open(\"issues.json\", \"r\") as file:\n",
    "    issue_dict = json.loads(file.read())\n",
    "    \n",
    "def get_participating_band_width(cdos, ionization_energy):\n",
    "    \n",
    "    dos = cdos.get_densities()\n",
    "    dos[cdos.energies < cdos.efermi - ionization_energy] = 0\n",
    "    dos[cdos.energies > cdos.efermi] = 0\n",
    "    energy_range = cdos.energies[np.nonzero(dos)]\n",
    "    return energy_range[-1] - energy_range[0]\n",
    "    \n",
    "for element in structure_dict.keys():\n",
    "    print(element)\n",
    "    \n",
    "    for surface in structure_dict[element][\"slabs\"].keys():\n",
    "        if not 'surface_' + surface + '_issue' in issue_dict[element]:\n",
    "            \n",
    "            quotas = QuotasCalculator.from_file(\"data/\" + element + \"_\" + surface + \"_pbe.json\")\n",
    "            yield_dict[element][surface] = calculate_yield(quotas)\n",
    "            yield_np_dict[element][surface] = calculate_yield(\n",
    "                quotas, plasmon_parameters={\"bulk\": 0, \"surface\": 0}\n",
    "            )\n",
    "            yield_dict[element][surface][\"work_function\"] = quotas.workfunction_data.work_function\n",
    "            yield_np_dict[element][surface][\"work_function\"] = quotas.workfunction_data.work_function\n",
    "            \n",
    "with open(\"yield.json\", \"w\") as file:\n",
    "    file.write(json.dumps(yield_dict, cls=MontyEncoder))\n",
    "with open(\"yield_np.json\", \"w\") as file:\n",
    "    file.write(json.dumps(yield_np_dict, cls=MontyEncoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results.json\", \"r\") as file:\n",
    "    results_dict = json.loads(file.read(), cls=MontyDecoder)\n",
    "    \n",
    "with open(\"yield.json\", \"r\") as file:\n",
    "    yield_dict = json.loads(file.read(), cls=MontyDecoder)\n",
    "\n",
    "with open(\"yield_np.json\", \"r\") as file:\n",
    "    yield_np_dict = json.loads(file.read(), cls=MontyDecoder)\n",
    "    \n",
    "for element in yield_dict.keys():\n",
    "    for surface in yield_dict[element].keys():\n",
    "        for ion in ionization_energies.keys():\n",
    "            band_width = get_participating_band_width(\n",
    "                results_dict[element][surface][\"complete_dos\"], ionization_energies[ion]\n",
    "            )\n",
    "            yield_dict[element][surface][ion].update({\"band_width\": band_width})\n",
    "            yield_np_dict[element][surface][ion].update({\"band_width\": band_width})\n",
    "\n",
    "with open(\"yield.json\", \"w\") as file:\n",
    "    file.write(json.dumps(yield_dict, cls=MontyEncoder))\n",
    "with open(\"yield_np.json\", \"w\") as file:\n",
    "    file.write(json.dumps(yield_np_dict, cls=MontyEncoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
